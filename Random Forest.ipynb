{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714c536e-ad92-4cee-99aa-5ec41220525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Random Forest Classification for Sentiment Prediction\n",
    "======================================================\n",
    "This notebook implements Random Forest models to predict overall and state-level \n",
    "sentiment based on economic indicators for Midwest states.\n",
    "\n",
    "Author: [Your Name]\n",
    "Date: [Date]\n",
    "Requirements: pandas, sklearn, matplotlib, seaborn\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# PART 1: INITIAL SETUP AND DATA LOADING\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset containing economic indicators and sentiment data\n",
    "# File should be in the same directory as this notebook\n",
    "Midwest = pd.read_csv(\"ModelData.csv\")\n",
    "\n",
    "# PART 2: DATA EXPLORATION AND PREPROCESSING\n",
    "\n",
    "# Display the first few rows to understand the data structure\n",
    "Midwest.head()\n",
    "\n",
    "# Create binary sentiment labels based on compound scores\n",
    "# Overall sentiment: positive if compound >= 0, negative otherwise\n",
    "def overall_sentiment(df):\n",
    "    \"\"\"\n",
    "    Convert overall compound sentiment scores to binary labels.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): Input dataframe with 'overall compound' column\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: Original dataframe with added 'overall sentiment' column\n",
    "    \"\"\"\n",
    "    df[\"overall sentiment\"] = df[\"overall compound\"].apply(\n",
    "        lambda x: \"positive\" if x >= 0 else \"negative\"\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# State-level sentiment: positive if compound >= 0, negative otherwise\n",
    "def state_sentiment(df):\n",
    "    \"\"\"\n",
    "    Convert state-level compound sentiment scores to binary labels.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): Input dataframe with 'state compound' column\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: Original dataframe with added 'state sentiment' column\n",
    "    \"\"\"\n",
    "    df[\"state sentiment\"] = df[\"state compound\"].apply(\n",
    "        lambda x: \"positive\" if x >= 0 else \"negative\"\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Apply sentiment labeling functions\n",
    "Midwest = overall_sentiment(Midwest)\n",
    "Midwest = state_sentiment(Midwest)\n",
    "\n",
    "# Display the processed dataframe\n",
    "Midwest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac49888-2a14-47ef-bb26-e7884da1112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 3: MODEL 1 - OVERALL SENTIMENT PREDICTION\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, \n",
    "    f1_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Initialize Random Forest classifier with Gini criterion\n",
    "# n_estimators=100: Use 100 decision trees in the forest\n",
    "# random_state=100: Set seed for reproducibility\n",
    "rforest1 = RandomForestClassifier(\n",
    "    criterion='gini', \n",
    "    n_estimators=100, \n",
    "    random_state=100\n",
    ")\n",
    "\n",
    "# Define features (economic indicators) and target (overall sentiment)\n",
    "X = Midwest[[\n",
    "    'mw_PCE',                # Personal Consumption Expenditures\n",
    "    'Unemployment',          # Unemployment rate\n",
    "    'mw_RealDispIncome',    # Real Disposable Income\n",
    "    'mw_wholesale_PPI',      # Wholesale Producer Price Index\n",
    "    'mw_supermarket_PPI',    # Supermarket Producer Price Index\n",
    "    'mw_produce_CPI',        # Produce Consumer Price Index\n",
    "    'mw_meat_CPI',          # Meat Consumer Price Index\n",
    "    'mw_diary_CPI'          # Dairy Consumer Price Index\n",
    "]]\n",
    "\n",
    "y = Midwest['overall sentiment']\n",
    "\n",
    "# Split data: 70% training, 30% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3, \n",
    "    random_state=100\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rforest1.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_rforest1_pred = rforest1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1423769-6df7-42a6-b314-c0262be4bd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 3: MODEL 1 - OVERALL SENTIMENT PREDICTION\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, \n",
    "    f1_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Initialize Random Forest classifier with Gini criterion\n",
    "# n_estimators=100: Use 100 decision trees in the forest\n",
    "# random_state=100: Set seed for reproducibility\n",
    "rforest1 = RandomForestClassifier(\n",
    "    criterion='gini', \n",
    "    n_estimators=100, \n",
    "    random_state=100\n",
    ")\n",
    "\n",
    "# Define features (economic indicators) and target (overall sentiment)\n",
    "X = Midwest[[\n",
    "    'mw_PCE',                # Personal Consumption Expenditures\n",
    "    'Unemployment',          # Unemployment rate\n",
    "    'mw_RealDispIncome',    # Real Disposable Income\n",
    "    'mw_wholesale_PPI',      # Wholesale Producer Price Index\n",
    "    'mw_supermarket_PPI',    # Supermarket Producer Price Index\n",
    "    'mw_produce_CPI',        # Produce Consumer Price Index\n",
    "    'mw_meat_CPI',          # Meat Consumer Price Index\n",
    "    'mw_diary_CPI'          # Dairy Consumer Price Index\n",
    "]]\n",
    "\n",
    "y = Midwest['overall sentiment']\n",
    "\n",
    "# Split data: 70% training, 30% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3, \n",
    "    random_state=100\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rforest1.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_rforest1_pred = rforest1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6f4ab3-ab66-4702-bbea-7f9117f13086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 4: MODEL 1 EVALUATION - CONFUSION MATRIX AND METRICS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_rforest1_pred)\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "confusion_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[\"Actual Negative\", \"Actual Positive\"],\n",
    "    columns=[\"Predicted Negative\", \"Predicted Positive\"]\n",
    ")\n",
    "\n",
    "# Plot confusion matrix as heatmap\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(confusion_df, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix - Overall Sentiment\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate per-class performance metrics\n",
    "metrics_table = pd.DataFrame({\n",
    "    \"Class\": [\"Negative\", \"Positive\"],\n",
    "    \"Precision\": [\n",
    "        precision_score(y_test, y_rforest1_pred, pos_label=\"negative\"),\n",
    "        precision_score(y_test, y_rforest1_pred, pos_label=\"positive\")\n",
    "    ],\n",
    "    \"Recall\": [\n",
    "        recall_score(y_test, y_rforest1_pred, pos_label=\"negative\"),\n",
    "        recall_score(y_test, y_rforest1_pred, pos_label=\"positive\")\n",
    "    ],\n",
    "    \"F1 Score\": [\n",
    "        f1_score(y_test, y_rforest1_pred, pos_label=\"negative\"),\n",
    "        f1_score(y_test, y_rforest1_pred, pos_label=\"positive\")\n",
    "    ],\n",
    "    \"Support (# Obs)\": [\n",
    "        sum(y_test == \"negative\"),\n",
    "        sum(y_test == \"positive\")\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Style the metrics table for better readability\n",
    "metrics_table_styled = (\n",
    "    metrics_table.style\n",
    "        .set_properties(**{\n",
    "            'font-size': '14px',\n",
    "            'padding': '8px',\n",
    "            'text-align': 'center'\n",
    "        })\n",
    "        .set_table_styles([\n",
    "            {'selector': 'th', \n",
    "             'props': [\n",
    "                 ('font-size', '16px'), \n",
    "                 ('font-weight', 'bold'), \n",
    "                 ('text-align', 'center'),\n",
    "                 ('background-color', '#1f4e79'),\n",
    "                 ('color', 'white'),\n",
    "                 ('padding', '10px')\n",
    "             ]},\n",
    "            {'selector': 'tbody tr:nth-child(even)',\n",
    "             'props': [('background-color', '#f2f6fc')]},\n",
    "            {'selector': 'tbody tr:nth-child(odd)',\n",
    "             'props': [('background-color', 'white')]},\n",
    "            {'selector': 'table',\n",
    "             'props': [\n",
    "                 ('border-collapse', 'collapse'),\n",
    "                 ('border', '1px solid #ccc'),\n",
    "                 ('border-radius', '8px'),\n",
    "                 ('overflow', 'hidden')\n",
    "             ]},\n",
    "        ])\n",
    "        .background_gradient(cmap=\"Blues\", subset=[\"Precision\", \"Recall\", \"F1 Score\"])\n",
    "        .format(\"{:.3f}\", subset=[\"Precision\", \"Recall\", \"F1 Score\"])\n",
    ")\n",
    "\n",
    "metrics_table_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb57f59-82d7-4d14-b75d-30793f2ed862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 5: FEATURE IMPORTANCE ANALYSIS\n",
    "\n",
    "# Extract feature names\n",
    "features = X.columns\n",
    "\n",
    "# Count distribution of sentiment classes\n",
    "positive_count = (y == \"positive\").sum()\n",
    "negative_count = (y == \"negative\").sum()\n",
    "\n",
    "# Create overall model performance summary\n",
    "results_table = pd.DataFrame({\n",
    "    \"Metric\": [\n",
    "        \"Accuracy\",\n",
    "        \"Precision (Macro)\",\n",
    "        \"Recall (Macro)\",\n",
    "        \"F1 (Macro)\",\n",
    "        \"Positive Count\",\n",
    "        \"Negative Count\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        accuracy_score(y_test, y_rforest1_pred),\n",
    "        precision_score(y_test, y_rforest1_pred, average='macro'),\n",
    "        recall_score(y_test, y_rforest1_pred, average='macro'),\n",
    "        f1_score(y_test, y_rforest1_pred, average='macro'),\n",
    "        positive_count,\n",
    "        negative_count\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Create feature importance table\n",
    "# Shows which economic indicators are most influential in predictions\n",
    "feature_importance_table = (\n",
    "    pd.DataFrame({\n",
    "        \"Feature\": features,\n",
    "        \"Importance\": rforest1.feature_importances_\n",
    "    })\n",
    "    .sort_values(\"Importance\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Style feature importance table\n",
    "feature_importance_pretty = (\n",
    "    feature_importance_table\n",
    "    .style.hide(axis='index')\n",
    "    .set_properties(**{\n",
    "        'background-color': '#eef7ff',\n",
    "        'border': '1px solid #bbb',\n",
    "        'padding': '6px'\n",
    "    })\n",
    "    .format({\"Importance\": \"{:.4f}\"})\n",
    ")\n",
    "\n",
    "feature_importance_pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968eba07-759a-4b5a-9143-97e233e89d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 6: MODEL 2 - STATE-LEVEL SENTIMENT PREDICTION\n",
    "\n",
    "# Redefine target variable for state-level sentiment\n",
    "y = Midwest['state sentiment']\n",
    "\n",
    "# Split data again with same parameters for consistency\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3, \n",
    "    random_state=100\n",
    ")\n",
    "\n",
    "# Train new model on state sentiment\n",
    "rforest1.fit(X_train, y_train)\n",
    "y_rforest1_pred = rforest1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b16ebcd-e81c-4571-80cb-4deb330d0f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 7: MODEL 2 EVALUATION\n",
    "\n",
    "# Repeat evaluation process for state sentiment model\n",
    "cm = confusion_matrix(y_test, y_rforest1_pred)\n",
    "\n",
    "confusion_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[\"Actual Negative\", \"Actual Positive\"],\n",
    "    columns=[\"Predicted Negative\", \"Predicted Positive\"]\n",
    ")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(confusion_df, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix - State Sentiment\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate metrics for state sentiment model\n",
    "metrics_table = pd.DataFrame({\n",
    "    \"Class\": [\"Negative\", \"Positive\"],\n",
    "    \"Precision\": [\n",
    "        precision_score(y_test, y_rforest1_pred, pos_label=\"negative\"),\n",
    "        precision_score(y_test, y_rforest1_pred, pos_label=\"positive\")\n",
    "    ],\n",
    "    \"Recall\": [\n",
    "        recall_score(y_test, y_rforest1_pred, pos_label=\"negative\"),\n",
    "        recall_score(y_test, y_rforest1_pred, pos_label=\"positive\")\n",
    "    ],\n",
    "    \"F1 Score\": [\n",
    "        f1_score(y_test, y_rforest1_pred, pos_label=\"negative\"),\n",
    "        f1_score(y_test, y_rforest1_pred, pos_label=\"positive\")\n",
    "    ],\n",
    "    \"Support (# Obs)\": [\n",
    "        sum(y_test == \"negative\"),\n",
    "        sum(y_test == \"positive\")\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Apply same styling\n",
    "metrics_table_styled = (\n",
    "    metrics_table.style\n",
    "        .set_properties(**{\n",
    "            'font-size': '14px',\n",
    "            'padding': '8px',\n",
    "            'text-align': 'center'\n",
    "        })\n",
    "        .set_table_styles([\n",
    "            {'selector': 'th', \n",
    "             'props': [\n",
    "                 ('font-size', '16px'), \n",
    "                 ('font-weight', 'bold'), \n",
    "                 ('text-align', 'center'),\n",
    "                 ('background-color', '#1f4e79'),\n",
    "                 ('color', 'white'),\n",
    "                 ('padding', '10px')\n",
    "             ]},\n",
    "            {'selector': 'tbody tr:nth-child(even)',\n",
    "             'props': [('background-color', '#f2f6fc')]},\n",
    "            {'selector': 'tbody tr:nth-child(odd)',\n",
    "             'props': [('background-color', 'white')]},\n",
    "            {'selector': 'table',\n",
    "             'props': [\n",
    "                 ('border-collapse', 'collapse'),\n",
    "                 ('border', '1px solid #ccc'),\n",
    "                 ('border-radius', '8px'),\n",
    "                 ('overflow', 'hidden')\n",
    "             ]},\n",
    "        ])\n",
    "        .background_gradient(cmap=\"Blues\", subset=[\"Precision\", \"Recall\", \"F1 Score\"])\n",
    "        .format(\"{:.3f}\", subset=[\"Precision\", \"Recall\", \"F1 Score\"])\n",
    ")\n",
    "\n",
    "metrics_table_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c50df24-6f62-42d5-af8c-5034703ff865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 8: FEATURE IMPORTANCE FOR STATE MODEL\n",
    "\n",
    "# Calculate feature importance for state sentiment model\n",
    "features = X.columns\n",
    "positive_count = (y == \"positive\").sum()\n",
    "negative_count = (y == \"negative\").sum()\n",
    "\n",
    "results_table = pd.DataFrame({\n",
    "    \"Metric\": [\n",
    "        \"Accuracy\",\n",
    "        \"Precision (Macro)\",\n",
    "        \"Recall (Macro)\",\n",
    "        \"F1 (Macro)\",\n",
    "        \"Positive Count\",\n",
    "        \"Negative Count\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        accuracy_score(y_test, y_rforest1_pred),\n",
    "        precision_score(y_test, y_rforest1_pred, average='macro'),\n",
    "        recall_score(y_test, y_rforest1_pred, average='macro'),\n",
    "        f1_score(y_test, y_rforest1_pred, average='macro'),\n",
    "        positive_count,\n",
    "        negative_count\n",
    "    ]\n",
    "})\n",
    "\n",
    "feature_importance_table = (\n",
    "    pd.DataFrame({\n",
    "        \"Feature\": features,\n",
    "        \"Importance\": rforest1.feature_importances_\n",
    "    })\n",
    "    .sort_values(\"Importance\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "feature_importance_pretty = (\n",
    "    feature_importance_table\n",
    "    .style.hide(axis='index')\n",
    "    .set_properties(**{\n",
    "        'background-color': '#eef7ff',\n",
    "        'border': '1px solid #bbb',\n",
    "        'padding': '6px'\n",
    "    })\n",
    "    .format({\"Importance\": \"{:.4f}\"})\n",
    ")\n",
    "\n",
    "feature_importance_pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906594ff-5c53-455e-9494-03ce6c612b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 9: VISUALIZING TRENDS - REAL DISPOSABLE INCOME OVER TIME\n",
    "\n",
    "# Convert Date column to datetime format for proper time series analysis\n",
    "Midwest['Date'] = pd.to_datetime(Midwest['Date'])\n",
    "\n",
    "# Extract year for grouping\n",
    "Midwest['Year'] = Midwest['Date'].dt.year\n",
    "\n",
    "# Create bar chart showing Real Disposable Income trends\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(\n",
    "    Midwest['Year'], \n",
    "    Midwest['mw_RealDispIncome'], \n",
    "    color='skyblue', \n",
    "    edgecolor='black'\n",
    ")\n",
    "\n",
    "# Add labels and formatting\n",
    "plt.xlabel(\"Year\", fontsize=12, fontweight='bold')\n",
    "plt.ylabel(\"Real Disposable Income\", fontsize=12, fontweight='bold')\n",
    "plt.title(\"Real Disposable Income Over Time\", fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='-', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
